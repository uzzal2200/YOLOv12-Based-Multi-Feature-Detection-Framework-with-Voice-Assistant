# A YOLOv12â€“ViT Hybrid-Based Multi-Feature Detection Framework with Voice Assistant 
## for Enhanced Mobility and Independence of Visually Impaired Persons

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg?style=flat-square&logo=python)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg?style=flat-square&logo=pytorch)](https://pytorch.org/)
[![YOLOv12](https://img.shields.io/badge/YOLOv12-Latest-green.svg?style=flat-square&logo=opencv)](https://github.com/ultralytics/ultralytics)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.5+-5C3EE8.svg?style=flat-square&logo=opencv)](https://opencv.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Active-success.svg?style=flat-square)]()

**Real-Time Multi-Modal Assistive Technology for Environmental Awareness**

[ğŸ“š Features](#-key-features) â€¢ [âš¡ Quick Start](#-quick-start) â€¢ [ğŸ’¾ Installation](#-installation--environment-setup) â€¢ [ğŸ“Š Datasets](#-datasets) â€¢ [ğŸ“– Citation](#-citation)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Datasets](#-datasets)
- [Models](#-models)
- [Installation & Environment Setup](#-installation--environment-setup)
- [Project Structure](#-project-structure)
- [License](#-license)

---

## ğŸ¯ Overview

This repository presents a **real-time multi-feature detection framework** engineered to enhance mobility and foster independence for visually impaired individuals. The system orchestrates **three specialized YOLOv12 object detection models** with an **intelligent multimodal voice feedback system**, delivering comprehensive environmental awareness including:

- ğŸš— **Object Detection** - Real-time identification of environmental objects
- ğŸ’µ **Currency Recognition** - Bangladeshi currency note denomination detection
- ğŸš¶ **Footpath Safety Assessment** - Sidewalk occupancy and safety evaluation
- ğŸ‘¤ **Face Recognition** - Known/Unknown person identification
- ğŸ“– **Optical Character Recognition** - Text detection with synthesized speech feedback

### ğŸŒŸ Key Innovation Attributes

âœ¨ **Multi-Task Learning Architecture**: Three concurrent YOLOv12 models optimized for speed and accuracy
ğŸŒ **Culturally Contextualized**: Designed specifically for Bangladeshi currency and language support
âš¡ **Real-Time Performance**: 15-30 FPS optimized for real-world deployment
ğŸ™ï¸ **Multimodal Feedback**: Hybrid pre-recorded + dynamic text-to-speech interface
â™¿ **Accessibility-Centric**: User-friendly interactive mode switching

---

## ğŸš€ Key Features

### Detection Capabilities

| Module | Detection Classes | Audio Output | Use Case |
|--------|------------------|--------------|----------|
| **Object Detection** | Vehicle, Chair, Door, Man, Road, Stair, Table, Tree, Wall (9 classes) | Pre-recorded MP3 | Environmental awareness |
| **Currency Detection** | 1Tk - 1000Tk denominations (9 classes) | Pre-recorded MP3 | Financial independence |
| **Footpath Safety** | Free/Occupied/Unsafe/Partial (4 classes) | Pre-recorded MP3 | Safe navigation |
| **Face Recognition** | Known/Unknown persons | Pre-recorded MP3 | Social interaction |
| **OCR Detection** | English text extraction | Dynamic Bangla gTTS | Information access |


---


## ğŸ“Š Datasets

### Dataset 1: Custom Object Detection
- **Source**: [Kaggle - Custom Object Detection Dataset](https://www.kaggle.com/datasets/uzzalhasan/custom-object-detection-dataset)
- **Classes**: 9 objects (Vehicle, Chair, Door, Man, Road, Stair, Table, Tree, Wall)
- **Format**: YOLO .txt annotation format
- **Application**: General environmental object detection

### Dataset 2: Bangladeshi Currency Detection
- **Source**: [Kaggle - BD Currency Dataset](https://www.kaggle.com/datasets/uzzalhasan/bd-currency)
- **Classes**: 10 denominations (1Tk, 2Tk, 5Tk, 10Tk, 20Tk, 50Tk, 100Tk, 200Tk, 500Tk, 1000Tk)
- **Format**: YOLO .txt annotation format
- **Application**: Currency denomination recognition for financial transactions

### Dataset 3: Footpath Detection
- **Source**: [Kaggle - Footpath Detection Dataset](https://www.kaggle.com/datasets/uzzalhasan/footpath-detection)
- **Classes**: 4 conditions (Free for use, Fully Occupied, Not safe for use, Partially Occupied)
- **Format**: YOLO .txt annotation format
- **Application**: Sidewalk safety assessment for navigation

### Dataset 4: Face Recognition Database
- **Storage**: `Known_unknown_detection/known_faces_folder/`
- **Format**: JPG/PNG image files
- **Application**: Person identification and social interaction

---

### 6. OCR Detection Module

```bash
python "OCR detection/OCR_Bangla_english.py"
```

---

## ğŸ“ Project Structure

```
object-text-detection-for-visually-impaired/
â”‚
â”œâ”€â”€ app.py                                    # Main real-time detection pipeline
â”œâ”€â”€ requirements.txt                          # Python dependencies
â”œâ”€â”€ LICENSE                                   # MIT License
â”œâ”€â”€ README.md                                 # This file
â”œâ”€â”€ .gitignore                                # Git ignore file
â”‚
â”œâ”€â”€ audio/                                    # Pre-recorded audio feedback files (26 files)
â”‚   â”œâ”€â”€ 1 tk.mp3, 2 taka.mp3, 5 tk.mp3, 10 Tk.mp3, 20 tk.mp3, 50 tk.mp3, 100 tk.mp3, 200 tk.mp3, 500 tk.mp3, 1000 tk.mp3  # Currency audio (10 files)
â”‚   â”œâ”€â”€ Vehicle.mp3, Chair.mp3, Door.mp3, Man.mp3, Road.mp3, Stair.mp3, Table.mp3, Tree.mp3, wall.mp3  # Object detection audio (9 files)
â”‚   â”œâ”€â”€ free for use.mp3, Fully Occupied .mp3, Partially Occupied .mp3, Not safe for use.mp3  # Footpath audio (4 files)
â”‚   â”œâ”€â”€ Known Face Uzzal .mp3, Unknown Face.mp3  # Face recognition audio (2 files)
â”‚   
â”‚
â”œâ”€â”€ Object detection Custom dataset/
â”‚   â”œâ”€â”€ custom_object_detection_with_yolov12n_pt.ipynb  # Training notebook
â”‚   â””â”€â”€ Save Model/
â”‚       â”œâ”€â”€ best.pt                          # Best trained YOLOv12 model
â”‚       â””â”€â”€ last.pt                          # Last checkpoint
â”‚
â”œâ”€â”€ Bangladesh Currency Detection/
â”‚   â”œâ”€â”€ Bangladeshi_Currency_detection_with_yolov12n_pt.ipynb  # Training notebook
â”‚   â””â”€â”€ Save Model/
â”‚       â””â”€â”€ best.pt                          # Trained currency detection model
â”‚
â”œâ”€â”€ Footpath Detection/
â”‚   â”œâ”€â”€ Footpath_detection_yolov12n_pt.ipynb  # Training notebook
â”‚   â””â”€â”€ Save Model/
â”‚       â””â”€â”€ best.pt                          # Trained footpath detection model
â”‚
â”œâ”€â”€ Known_unknown_detection/
â”‚   â”œâ”€â”€ known_unknown_detection.py           # Face recognition detection script
â”‚   â”œâ”€â”€ evaluation_metrices.py               # Evaluation metrics for face detection
â”‚   â”œâ”€â”€ known_faces_folder/                  # Database of known person face images
â”‚   â””â”€â”€ .venv/                               # Virtual environment
â”‚
â”œâ”€â”€ OCR detection/
â”‚   â”œâ”€â”€ OCR_Bangla_english.py                # OCR text detection script
â”‚   â”œâ”€â”€ evaluation_metrices.py               # Evaluation metrics for OCR
â”‚   â””â”€â”€ __pycache__/                         # Python cache files
â”‚
â”œâ”€â”€ .git/                                     # Git version control repository
â”‚
â””â”€â”€ YOLOv12_Based_Multi_Feature_Detection...pdf  # Research paper PDF
```

---


## ğŸ“œ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Ultralytics** for YOLOv12 framework
- **dlib** community for face recognition
- **Tesseract-OCR** project for text detection
- **Kaggle** for dataset resources
- **Open source community** for PyTorch, OpenCV, and other dependencies

---

## ğŸ“ Support & Contribution

For issues, feature requests, or contributions, please open an issue or submit a pull request on GitHub.

**Last Updated**: January 27, 2026
